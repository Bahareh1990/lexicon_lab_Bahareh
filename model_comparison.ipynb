{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdb07910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This notebook aims to compare the performance of two semantic models: word2vec and speech2vec.\n",
    "We will use the Static Foraging Model and the previous data and models to measure the performance.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bae9ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Necessary imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from scipy.optimize import fmin\n",
    "from foraging import forage\n",
    "from cues import create_history_variables\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin\n",
    "import os, sys\n",
    "from tqdm import tqdm\n",
    "import lexicon_lab_Bahareh\n",
    "from lexicon_lab_Bahareh import Similarity, Clusters\n",
    "from foraging import forage\n",
    "from collections import Counter\n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23bd3373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load similarity data\n",
    "cosine_similarity_data = pd.read_csv('results/cosine_similarity_results.csv')\n",
    "pairwise_similarity_data = pd.read_csv('results/pairwise_similarity_results.csv')\n",
    "\n",
    "# Split the data based on model\n",
    "word2vec_cosine_similarities = cosine_similarity_data[cosine_similarity_data['Model'] == 'word2vec']['Similarity'].values\n",
    "speech2vec_cosine_similarities = cosine_similarity_data[cosine_similarity_data['Model'] == 'speech2vec']['Similarity'].values\n",
    "\n",
    "word2vec_pairwise_similarities = pairwise_similarity_data[pairwise_similarity_data['Model'] == 'word2vec']['Similarity'].values\n",
    "speech2vec_pairwise_similarities = pairwise_similarity_data[pairwise_similarity_data['Model'] == 'speech2vec']['Similarity'].values\n",
    "\n",
    "# Frequency data loading code\n",
    "\n",
    "def get_frequencies(input_file, output_file):\n",
    "    with open(input_file, 'r') as f_in, open(output_file, 'w') as f_out:\n",
    "        writer = csv.writer(f_out)\n",
    "        for line in f_in:\n",
    "            word, *vector = line.strip().split(' ')\n",
    "            vector = list(map(float, vector))\n",
    "            counts = Counter(i for i, value in enumerate(vector) if abs(value) > 0.5)\n",
    "            for index, count in counts.items():\n",
    "                writer.writerow([word, index, count])\n",
    "\n",
    "get_frequencies('word2vec.txt', 'word2vec_frequencies.csv')\n",
    "get_frequencies('speech2vec.txt', 'speech2vec_frequencies.csv')\n",
    "\n",
    "\n",
    "# Load word2vec frequencies\n",
    "word2vec_frequencies_df = pd.read_csv('word2vec_frequencies.csv', names=['word', 'index', 'count'])\n",
    "\n",
    "# Load speech2vec frequencies\n",
    "speech2vec_frequencies_df = pd.read_csv('speech2vec_frequencies.csv', names=['word', 'index', 'count'])\n",
    "\n",
    "# Load frequency data into dictionaries\n",
    "word2vec_frequencies_dict = word2vec_frequencies_df.groupby('word')['count'].sum().to_dict()\n",
    "speech2vec_frequencies_dict = speech2vec_frequencies_df.groupby('word')['count'].sum().to_dict()\n",
    "\n",
    "# Load cosine similarity data\n",
    "cosine_data = pd.read_csv('results/cosine_similarity_results.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa5f0e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that 'word' in the pairwise_similarity_data is representative of the words\n",
    "# in the experiment, you can extract the frequencies for the words in the order they appear:\n",
    "word2vec_frequencies = [word2vec_frequencies_dict.get(word, 0) for word in pairwise_similarity_data[pairwise_similarity_data['Model'] == 'word2vec']['Word']]\n",
    "speech2vec_frequencies = [speech2vec_frequencies_dict.get(word, 0) for word in pairwise_similarity_data[pairwise_similarity_data['Model'] == 'speech2vec']['Word']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3bff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "beta = (0.5, 0.5)  # Both beta_frequency and beta_semantic set to 0.5 as an example\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0502132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#modify the model static\n",
    "def model_static(beta, freql, freqh, siml, simh):\n",
    "    \n",
    "    ct = 0\n",
    "    all_zero_denrat = True\n",
    "    for k in range(0, len(freql)):\n",
    "        if k == 0:\n",
    "            numrat = pow(freql[k], beta[0])\n",
    "            denrat = sum(pow(freqh[i], beta[0]) for i in range(k+1))\n",
    "        else:    \n",
    "            numrat = pow(freql[k], beta[0]) * pow(siml[k], beta[1])\n",
    "            denrat = sum(pow(freqh[i], beta[0]) * pow(simh[i], beta[1]) for i in range(k+1))\n",
    "        \n",
    "        # Check for denrat being zero and handle it\n",
    "        if denrat == 0:\n",
    "            print(f\"denrat is zero at index {k}!\")\n",
    "            prob = 0\n",
    "        else:\n",
    "            all_zero_denrat = False\n",
    "            prob = numrat/denrat\n",
    "        \n",
    "        ct -= np.log(prob + 1e-10)  # Small constant added to prevent log(0)\n",
    "\n",
    "    if all_zero_denrat:\n",
    "        return float('inf')  # Extremely large negative log-likelihood\n",
    "\n",
    "    return ct\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33d327f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denrat is zero at index 0!\n",
      "denrat is zero at index 1!\n",
      "denrat is zero at index 2!\n",
      "denrat is zero at index 3!\n",
      "denrat is zero at index 4!\n",
      "denrat is zero at index 5!\n",
      "denrat is zero at index 6!\n",
      "denrat is zero at index 7!\n",
      "denrat is zero at index 8!\n",
      "denrat is zero at index 9!\n",
      "denrat is zero at index 10!\n",
      "denrat is zero at index 11!\n",
      "denrat is zero at index 12!\n",
      "denrat is zero at index 13!\n",
      "denrat is zero at index 14!\n",
      "denrat is zero at index 15!\n",
      "denrat is zero at index 16!\n",
      "denrat is zero at index 17!\n",
      "denrat is zero at index 18!\n",
      "denrat is zero at index 19!\n",
      "denrat is zero at index 20!\n",
      "denrat is zero at index 21!\n",
      "denrat is zero at index 22!\n",
      "denrat is zero at index 23!\n",
      "denrat is zero at index 24!\n",
      "denrat is zero at index 25!\n",
      "denrat is zero at index 26!\n",
      "denrat is zero at index 27!\n",
      "denrat is zero at index 28!\n",
      "denrat is zero at index 0!\n",
      "denrat is zero at index 1!\n",
      "denrat is zero at index 2!\n",
      "denrat is zero at index 3!\n",
      "denrat is zero at index 4!\n",
      "denrat is zero at index 5!\n",
      "denrat is zero at index 6!\n",
      "denrat is zero at index 7!\n",
      "denrat is zero at index 8!\n",
      "denrat is zero at index 9!\n",
      "denrat is zero at index 10!\n",
      "denrat is zero at index 11!\n",
      "denrat is zero at index 12!\n",
      "denrat is zero at index 13!\n",
      "denrat is zero at index 14!\n",
      "denrat is zero at index 15!\n",
      "denrat is zero at index 16!\n",
      "denrat is zero at index 17!\n",
      "denrat is zero at index 18!\n",
      "denrat is zero at index 19!\n",
      "denrat is zero at index 20!\n",
      "denrat is zero at index 21!\n",
      "denrat is zero at index 22!\n",
      "denrat is zero at index 23!\n",
      "denrat is zero at index 24!\n",
      "denrat is zero at index 25!\n",
      "denrat is zero at index 26!\n",
      "denrat is zero at index 27!\n",
      "denrat is zero at index 28!\n",
      "Negative Log-Likelihood for word2vec: 16446.627511091818\n",
      "Negative Log-Likelihood for speech2vec: 15738.226929820421\n",
      "speech2vec is a better model for the data.\n"
     ]
    }
   ],
   "source": [
    "nll_word2vec = model_static(beta, word2vec_frequencies, word2vec_frequencies, word2vec_pairwise_similarities, word2vec_pairwise_similarities)\n",
    "nll_speech2vec = model_static(beta, speech2vec_frequencies, speech2vec_frequencies, speech2vec_pairwise_similarities, speech2vec_pairwise_similarities)\n",
    "\n",
    "print(f\"Negative Log-Likelihood for word2vec: {nll_word2vec}\")\n",
    "print(f\"Negative Log-Likelihood for speech2vec: {nll_speech2vec}\")\n",
    "\n",
    "# The lower value indicates the better model:\n",
    "if nll_word2vec < nll_speech2vec:\n",
    "    print(\"word2vec is a better model for the data.\")\n",
    "else:\n",
    "    print(\"speech2vec is a better model for the data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00c5c7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNegative Log-Likelihood for word2vec: 16446.62750621399\\nNegative Log-Likelihood for speech2vec: 15738.226932408608\\nspeech2vec is a better model for the data.\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Negative Log-Likelihood for word2vec: 16446.627511091818\n",
    "Negative Log-Likelihood for speech2vec: 15738.226929820421\n",
    "speech2vec is a better model for the data.\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
