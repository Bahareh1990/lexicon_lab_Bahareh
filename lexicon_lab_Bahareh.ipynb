{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8055316d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#!pip install gensim numpy pandas matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c67142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#: Import required libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity as sklearn_cos_sim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from switch import switch_simdrop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c51c2e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAF-657</td>\n",
       "      <td>lizard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAF-657</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAF-657</td>\n",
       "      <td>hawk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAF-657</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAF-657</td>\n",
       "      <td>turtle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>SZA-781</td>\n",
       "      <td>puppy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>SZA-781</td>\n",
       "      <td>kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>SZA-781</td>\n",
       "      <td>goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>SZA-781</td>\n",
       "      <td>duck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>SZA-781</td>\n",
       "      <td>wolf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1307 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Participant    Word\n",
       "0        CAF-657  lizard\n",
       "1        CAF-657     cat\n",
       "2        CAF-657    hawk\n",
       "3        CAF-657     dog\n",
       "4        CAF-657  turtle\n",
       "...          ...     ...\n",
       "1302     SZA-781   puppy\n",
       "1303     SZA-781  kitten\n",
       "1304     SZA-781   goose\n",
       "1305     SZA-781    duck\n",
       "1306     SZA-781    wolf\n",
       "\n",
       "[1307 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to load embeddings\n",
    "def load_embeddings(file_path):\n",
    "    embeddings = {}\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "\n",
    "# Load model_vectors data\n",
    "word2vec_vectors = load_embeddings('word2vec.txt')\n",
    "speech2vec_vectors = load_embeddings('speech2vec.txt')\n",
    "\n",
    "\n",
    "\n",
    "# Load participant data\n",
    "data = pd.read_csv('data-cochlear.txt', sep='\\t', names=['Participant', 'Word'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5a42331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "class Similarity:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def cosine_similarity_func(self, word1, word2, embeddings):\n",
    "        vector1, vector2 = None, None\n",
    "        \n",
    "        if word1 in embeddings and word2 in embeddings:\n",
    "            vector1 = embeddings[word1]\n",
    "            vector2 = embeddings[word2]\n",
    "\n",
    "        if vector1 is None or vector2 is None:\n",
    "            return 0\n",
    "\n",
    "        return cosine_similarity([vector1], [vector2])[0][0]\n",
    "\n",
    "\n",
    "    def get_vector(self, model, word, default_size=50):  # set default vector size to 50\n",
    "        if word in model:\n",
    "            vec = np.array(model[word]).reshape(1, -1)\n",
    "\n",
    "            return vec, vec.shape[1]\n",
    "        else:\n",
    "            return np.zeros((1, default_size)), default_size\n",
    "\n",
    "    def pairwise_similarity(self, data, model, model_name):\n",
    "        # Calculate the pairwise similarity between each consecutive word produced by participants based on the provided model\n",
    "        unique_ids = data['ID'].unique()\n",
    "        results = []\n",
    "\n",
    "        for uid in unique_ids:\n",
    "            current_word = data.loc[data['ID'] == uid, 'Word'].iloc[0]\n",
    "            similarities = []\n",
    "            for word in data.loc[data['ID'] == uid, 'Word']:\n",
    "                if word != current_word:\n",
    "                    vec1, _ = self.get_vector(model, current_word)\n",
    "                    vec2, _ = self.get_vector(model, word)\n",
    "                    similarity = self.cosine_similarity_func(current_word, word, model)\n",
    "                    similarities.append(float(similarity))\n",
    "                else:\n",
    "                    similarities.append(2)\n",
    "            results.append((uid, word, similarities, model_name))\n",
    "\n",
    "        pairwise_sim_df = pd.DataFrame(results, columns=['ID', 'Word', 'Similarities', 'Model'])\n",
    "        return pairwise_sim_df\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37515078",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "class Clusters:\n",
    "    def __init__(self):\n",
    "        self.cluster_data = {}\n",
    "\n",
    "    def compute_clusters(self, data, word2vec, speech2vec):\n",
    "        cluster_data = {}\n",
    "        \n",
    "        for model_name, model in [(\"word2vec\", word2vec), (\"speech2vec\", speech2vec)]:\n",
    "            similarity = Similarity()\n",
    "            sim_data = similarity.pairwise_similarity(data, model, model_name)\n",
    "            sim_scores = [item for sublist in sim_data['Similarities'].tolist() for item in sublist]  # Flatten the similarities list\n",
    "            switches = switch_simdrop(data['Word'].tolist(), sim_scores)\n",
    "            cluster_data[model_name] = switches\n",
    "            \n",
    "        self.cluster_data = cluster_data  # Assigning results to the class attribute\n",
    "        \n",
    "    def visualize_clusters(self, save_path=\"results/cluster_comparison.png\"):\n",
    "        # Calculate means for both models\n",
    "        means = {}\n",
    "        for model_name, results in self.cluster_data.items():\n",
    "            cluster_values = [result for result in results if result != 2]\n",
    "            switch_values = [result for result in results if result == 1]\n",
    "            means[model_name] = {\n",
    "                \"Clusters\": np.mean(cluster_values) if cluster_values else 0,\n",
    "                \"Switches\": np.mean(switch_values) if switch_values else 0\n",
    "            }\n",
    "\n",
    "        # Extract means for plotting\n",
    "        word2vec_means = [means['word2vec']['Clusters'], means['word2vec']['Switches']]\n",
    "        speech2vec_means = [means['speech2vec']['Clusters'], means['speech2vec']['Switches']]\n",
    "\n",
    "        # Create the bar plot\n",
    "        barWidth = 0.3\n",
    "        r1 = np.arange(len(word2vec_means))\n",
    "        r2 = [x + barWidth for x in r1]\n",
    "\n",
    "        plt.bar(r1, word2vec_means, color='b', width=barWidth, edgecolor='grey', label='word2vec')\n",
    "        plt.bar(r2, speech2vec_means, color='r', width=barWidth, edgecolor='grey', label='speech2vec')\n",
    "        \n",
    "        plt.xlabel('Metrics', fontweight='bold')\n",
    "        plt.xticks([r + barWidth for r in range(len(word2vec_means))], ['Clusters', 'Switches'])\n",
    "        plt.legend()\n",
    "\n",
    "        if not os.path.exists('results'):\n",
    "            os.makedirs('results')\n",
    "        plt.savefig(save_path)\n",
    "        plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
